(Concerning to original README.md, please refer to README_ORIG.md.)
# Implementation of *Fast* R-CNN on Another Dataset: [Right Whale Recognition](https://www.kaggle.com/c/noaa-right-whale-recognition)
Before starting to train your Fast-RCNN on another dataset with this tutorial, in order to avoid unknown errors which are unrelated to these steps, please ensure you've followed the original steps to reproduce the result of demo successfully.

## Preparing Dataset
Following the steps list on [Train Fast-RCNN on Another Dataset](https://github.com/zeyuanxy/fast-rcnn/tree/master/help/train) and [How to train fast rcnn on imagenet](http://sunshineatnoon.github.io/Train-fast-rcnn-model-on-imagenet-without-matlab/), prepare your own dataset.

Below is my dataset directory:
```
kaggle
|-- data
    |-- train.mat
    |-- Annotations
         |-- *.xml (Annotation files)
    |-- Images
         |-- *.JPEG (Image files)
    |-- ImageSets
         |-- train.txt
```
- train.mat: This is the selective search proposals file, which generated by either `selective_search.m` in `$FRCNN_ROOT/selective_search`
- Annotations: This folder contains all annotation files of the images, in my implementation, it is in xml format. There's only one object (right whale's face) and one class I should to describe. Below is the example:
```
<? w_819.xml ?>
<annotation>
  <folder>kaggle</folder>
    <filename>
      <item>w_819.jpg</item>
    </filename>
    <object>
      <name>whale</name>
      <bndbox>
        <xmin>1277</xmin>
        <ymin>568</ymin>
        <xmax>1554</xmax>
        <ymax>961</ymax>
      </bndbox>
    </object>
</annotation>
```
- Images: This folder contains all images
- ImageSets: This folder originally only contains one file--trian.txt, which contains all the names of the images. It looks like this:
```
w_8762
w_3935
w_1087
...
```
while I add another file--test.txt having the same format as train.txt to store the file names of the test data.

## Construct IMDB File
### `kaggle.py`
We have to create a file `kaggle.py` in the directory `$FRCNN_ROOT/lib/datasets`, where `$FRCNN_ROOT` is your path to fast-rcnn directory, e.g. `/home/coldmanck/fast-rcnn`. This file defines some functions which tell fast rcnn how to read ground truth boxes and how to find images on disk. Following the example file [inria.py](https://github.com/EdisonResearch/fast-rcnn/blob/master/lib/datasets/inria.py) created by [zeyuanxy's instruction](https://github.com/zeyuanxy/fast-rcnn/tree/master/help/train) , I mainly modified some functions below. You may want to read along with my file [kaggle.py](https://github.com/coldmanck/fast-rcnn/blob/master/lib/datasets/kaggle.py).

**In function `__init__(self, image_set, devkit_path)`**

Modify the classes name and picture format to fit the dataset.
```
self._classes = ('__background__', 'whale')
self._image_ext = '.jpg'
```

**In function `image_path_from_index(self, index)`**

Revise the code to train on only **one** class. Note that if you would like to detect multiple classes, do not modify anything here.
```
image_path = os.path.join(self._data_path,'Images',index+self._image_ext)
assert os.path.exists(image_path), 'Path does not exist: {}'.format(image_path)
return image_path
```

**In function `_load_imagenet_annotation`**

This is th function for parsing annotations which should be figured out carefully. Here, I follow the instruction of [sunshinearnoon](http://sunshineatnoon.github.io/Train-fast-rcnn-model-on-imagenet-without-matlab/), define a new inner-function to get the tags from xml files.
```
def get_data_from_tag(node,tag):
  return node.getElementsByTagName(tag)[0].childNodes[0].data
```
Then, modifying codes to get annotations by this function. For detail, see my [kaggle.py](https://github.com/coldmanck/fast-rcnn/blob/master/lib/datasets/kaggle.py).

Also, in the for loop of process of loading object bounding boxes into a data frame, there're something should be modified. Refer to the issue of selective search, one may find that 
- the format of proposal ROIs produced by matlab code is: [top, left, bottom, right], 1-based index.
- while the format of proposals in demo mat file is: [left, top, right, bottom], 0-based index.
In our training and testing process, in fact, we follow the first second format **[left, top, right, bottom], 0-based index**. One may see in function `_load_selective_search_roidb`: there's a line `box_list.append(raw_data[i][:, (1, 0, 3, 2)] - 1)` which dealing with this problem.

Also, because the data format of Right Whale dataset which coordinates start from zero, is different from the original format, I need to minus one to fit:
```
x1 = float(get_data_from_tag(obj, 'xmin')) - 1
y1 = float(get_data_from_tag(obj, 'ymin')) - 1
x2 = float(get_data_from_tag(obj, 'xmax')) - 1
y2 = float(get_data_from_tag(obj, 'ymax')) - 1
```
### `factory.py`
There're some lines you have to modify:
```
import datasets.kaggle

# Set up kaggle_<split> using selective search "fast" mode
kaggle_devkit_path = '/home/coldmanck/kaggle'
for split in ['train', 'test']:
    name = '{}_{}'.format('kaggle', split)
    __sets[name] = (lambda split=split: datasets.kaggle(split, kaggle_devkit_path))
```
If you have more than one class you have to deal with, `numbers_of_classes` for-loop you have to create. You can refer to my `factory.py` [here](https://github.com/coldmanck/fast-rcnn/blob/master/lib/datasets/factory.py) (one class) and original `factory_inria.py` created by zeyuanxy [here](https://github.com/coldmanck/fast-rcnn/blob/master/lib/datasets/factory_inria.py) (two classes).

## Run Selective Search
If you have MATLAB, you may find original approach easy for you to implement. Modify the matlab file `selective_search.m` in the directory `$FRCNN_ROOT/selective_search`, If you do not have that directory, you could find it [here](https://github.com/EdisonResearch/fast-rcnn/tree/master/selective_search)).
```
image_db = '/home/coldmanck/kaggle';
    image_filenames = textread([image_db '/data/ImageSets/train.txt'], '%s', 'delimite    r', '\n');
    for i = 1:length(image_filenames)
        if exist([image_db '/data/Images/' image_filenames{i} '.jpg'], 'file') == 2
        image_filenames{i} = [image_db '/data/Images/' image_filenames{i} '.jpg'];
    end
    if exist([image_db '/data/Images/' image_filenames{i} '.png'], 'file') == 2
        image_filenames{i} = [image_db '/data/Images/' image_filenames{i} '.png'];
    end
end
selective_search_rcnn(image_filenames, 'train.mat');
```
Then run this mat to generate proposals of training data, then move the output `train.mat` to the root of your dataset, e.g. `/home/coldmanck/kaggle`. It's time-consuming and highly depends on performance of your machine, wait patiently :-)

If you don't have MATLAB, [dlib's slective search](http://dlib.net/) is recommended, you can find details in [sunshineatnoon's instruction](http://sunshineatnoon.github.io/Train-fast-rcnn-model-on-imagenet-without-matlab/).

## Modify Prototxt
**Note these steps are important** for someone who may encountered error like `Check failed: ShapeEquals(proto) shape mismatch(reshape not set)`. This is my solution after encountering above error. If you followed the instruction of [Train Fast-RCNN on Another Dataset](https://github.com/zeyuanxy/fast-rcnn/tree/master/help/train) or [How to train fast rcnn on imagenet](http://sunshineatnoon.github.io/Train-fast-rcnn-model-on-imagenet-without-matlab/) but encountered the same error, consider to follow my instruction here.
First, 
Sine I have ony two classes(**background** and **kaggle**), I need to change the network structure. Depending on which pre-trained model you would like to train on, modify files in `$FRCNN_ROOT/models/{CaffeNet, VGG16, VGG_CNN_M_1024}/train.prototxt` to fit the dataset.

For the input layer, we need to change input class to 2: param_str: `'num_classes': 2`
For the clsscore layer, we need to change output class to 2: `numoutput: 2`
For the bboxpred layer, we need to change output to 2*4=8: `numoutput: 18`
See my [test_kaggle.prototxt](https://github.com/coldmanck/fast-rcnn/blob/master/models/VGG16/test_kaggle.prototxt) file for reference.





## Reference
1. [Train Fast-RCNN on Another Dataset](https://github.com/zeyuanxy/fast-rcnn/tree/master/help/train)
2. [How to train fast rcnn on imagenet](http://sunshineatnoon.github.io/Train-fast-rcnn-model-on-imagenet-without-matlab/)
3. [Selective Search Configuration](https://github.com/rbgirshick/fast-rcnn/issues/26)
4. [Fast rcnn 訓練自己的數據庫問題小結](http://blog.csdn.net/hao529good/article/details/46544163)
